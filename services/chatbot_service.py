import os
import openai
from services.faiss_manager import FAISSManager
from dotenv import load_dotenv

load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")

def get_chatbot_response(query: str) -> str:
    print(f"üß† Recibida pregunta: {query}")
    
    faiss_manager = FAISSManager()
    db = faiss_manager.load_index()

    if not db:
        print("‚ùå No se encontr√≥ el √≠ndice FAISS.")
        return "Todav√≠a no hay informaci√≥n cargada."

    try:
        resultados = db.similarity_search(query, k=5)
        contexto = "\n".join([doc.page_content for doc in resultados])
        print(f"üîç Fragmentos encontrados: {len(resultados)}")
        print("üßæ Contexto generado:")
        print(contexto)
    except Exception as e:
        print(f"‚ö†Ô∏è Error al buscar en FAISS: {e}")
        return f"Error al buscar contexto: {e}"

    prompt = f"""
Contesta la siguiente pregunta bas√°ndote solamente en la informaci√≥n proporcionada.
---
Informaci√≥n:
{contexto}
---
Pregunta: {query}
Respuesta:
""".strip()

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Sos un asistente que responde solo con la informaci√≥n dada."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=500,
        )
        print("‚úÖ Respuesta generada correctamente.")
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"‚ùå Error con la API de OpenAI: {e}")
        return f"Error al conectarse con OpenAI: {e}"
